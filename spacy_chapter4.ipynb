{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00f223df-2126-46f7-a185-6269afb6def0",
   "metadata": {},
   "source": [
    "#### Advanced NLP with spaCy\n",
    "#### Chapter 4: Training a neural network model\n",
    "##### Training and updating models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debfbafb-448e-4168-9f7a-dabf6648f6d4",
   "metadata": {},
   "source": [
    "Training is typically used for better results in a specific domain.  \n",
    "Training is essential for text classification.  \n",
    "Also pretty important for entity recognition.  \n",
    "It is less critical for tagging and parsing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cf9597-f2fd-493b-908b-47b5b75b781e",
   "metadata": {},
   "source": [
    "Training steps:\n",
    "1. Initialize weights randomly\n",
    "1. Predict examples with current weights\n",
    "1. Compare prediction with correct labels\n",
    "1. Calculate how to change weights to improve predictions\n",
    "1. Update weights slightly\n",
    "1. Repeat for appropriate epochs\n",
    "\n",
    "Spacy supports fine-tuning existing models and new models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abb93df-9ce9-4da4-ad59-dcdc3b98eb7e",
   "metadata": {},
   "source": [
    "Labeling entities:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "089e3714-7478-4317-a415-912f6cbbb054",
   "metadata": {},
   "source": [
    "doc = nlp(\"iPhone X is coming\")\n",
    "doc.ents = [Span(doc, 0, 2, label=\"GADGET\")]\n",
    "doc = nlp(\"I need a new phone! Any tips?\")\n",
    "doc.ents = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cd27f1-9225-4b40-b5e4-5e0162785c84",
   "metadata": {},
   "source": [
    "Use the DocBin object to serialize the training and evaluation data to disk (faster than pickle):"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a2047600-9ce0-444b-9210-e3af6b677520",
   "metadata": {},
   "source": [
    "train_docbin = DocBin(docs=training_data))\n",
    "train_docbin.to_disk(\"./training.spacy\")\n",
    "dev_docbin = DocBin(docs=dev_docs)\n",
    "dev_docbin.to_disk(\"./dev.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d283787-c1ce-4e38-9459-bf903b8b2822",
   "metadata": {},
   "source": [
    "Some common formats are CoNLL (.conll, .conllu) and IOB (.iob).  \n",
    "Spacy provides a conversion command for them:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8707a835-86d2-4f7a-9819-091190e41a6f",
   "metadata": {},
   "source": [
    "python -m spacy convert ./train.gold.conll ./corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2a9f60-741e-483f-986a-ad8846ecfe01",
   "metadata": {},
   "source": [
    "This command also works for spaCy's old json format from v2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99580761-e354-4a0e-b029-6c25def4ef96",
   "metadata": {},
   "source": [
    "##### Creating training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a70157d-52d0-45a4-912d-7ebd10d496b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iPhone X]\n",
      "[iPhone X]\n",
      "[iPhone X]\n",
      "[iPhone 8]\n",
      "[iPhone 11, iPhone 8]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span, DocBin\n",
    "\n",
    "TEXTS = [\n",
    "  \"How to preorder the iPhone X\",\n",
    "  \"iPhone X is coming\",\n",
    "  \"Should I pay $1,000 for the iPhone X?\",\n",
    "  \"The iPhone 8 reviews are here\",\n",
    "  \"iPhone 11 vs iPhone 8: What's the difference?\",\n",
    "  \"I need a new phone! Any tips?\"\n",
    "]\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pattern1 = [{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}]\n",
    "pattern2 = [{\"LOWER\": \"iphone\"}, {\"IS_DIGIT\": True}]\n",
    "\n",
    "matcher.add(\"GADGET\", [pattern1, pattern2])\n",
    "docs = []\n",
    "for doc in nlp.pipe(TEXTS):\n",
    "    matches = matcher(doc)\n",
    "    spans = [Span(doc, start, end, label=match_id) for match_id, start, end in matches]\n",
    "    print(spans)\n",
    "    doc.ents = spans\n",
    "    docs.append(doc)\n",
    "\n",
    "doc_bin = DocBin(docs=docs)\n",
    "# doc_bin.to_disk(\"./train.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd06215f-17ce-4ea5-b80b-2c844675ed62",
   "metadata": {},
   "source": [
    "##### Configuring and running the training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33216e31-13e4-4067-ac2e-8f5c7a2aba72",
   "metadata": {},
   "source": [
    "Spacy using a config file usually named config.cfg as a single source or truth to initialize the nlp object.\n",
    "- pipeline components and their models\n",
    "- training process and hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c09d70-df92-475a-99b8-184f734276c1",
   "metadata": {},
   "source": [
    "Example config (@ sign references a python function):"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c19d9247-6e8b-4cc7-9677-a5b5c8960ebc",
   "metadata": {},
   "source": [
    "[nlp]\n",
    "lang = \"en\"\n",
    "pipeline = [\"tok2vec\", \"ner\"]\n",
    "batch_size = 1000\n",
    "\n",
    "[nlp.tokenizer]\n",
    "@tokenizers = \"spacy.Tokenizer.v1\"\n",
    "\n",
    "[components]\n",
    "\n",
    "[components.ner]\n",
    "factory = \"ner\"\n",
    "\n",
    "[components.ner.model]\n",
    "@architectures = \"spacy.TransitionBasedParser.v2\"\n",
    "hidden_width = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc90451-c575-48c9-9a7d-d12775b5ae75",
   "metadata": {},
   "source": [
    "To create a file interactively use:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c869413a-3e18-4d4f-ac19-f029be301f4f",
   "metadata": {},
   "source": [
    "python -m spacy init config ./config.cfg --args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c3db87-e2d8-476e-83f8-0bb4cd38cbe3",
   "metadata": {},
   "source": [
    "To train a model from spacy files:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ca43094-6419-446f-8f29-2fa6df2fa309",
   "metadata": {},
   "source": [
    "python -m spacy train ./config.cfg --output ./output --paths.train train.spacy --paths.dev dev.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c6b240-ca00-4a5f-bd4e-bd1245abe1a5",
   "metadata": {},
   "source": [
    "Example output:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c60b6356-98de-4bbf-98a8-314759a8491b",
   "metadata": {},
   "source": [
    "============================ Training pipeline ============================\n",
    "ℹ Pipeline: ['tok2vec', 'ner']\n",
    "ℹ Initial learn rate: 0.001\n",
    "\n",
    "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE\n",
    "---  ------  ------------  --------  ------  ------  ------  ------\n",
    "  0       0          0.00     26.50    0.73    0.39    5.43    0.01\n",
    "  0     200         33.58    847.68   10.88   44.44    6.20    0.11\n",
    "  1     400         70.88    267.65   33.50   45.95   26.36    0.33\n",
    "  2     600         67.56    156.63   45.32   62.16   35.66    0.45\n",
    "  3     800        138.28    134.12   48.17   74.19   35.66    0.48\n",
    "  4    1000        177.95    109.77   51.43   66.67   41.86    0.51\n",
    "  6    1200         94.95     52.13   54.63   67.82   45.74    0.55\n",
    "  8    1400        126.85     66.19   56.00   65.62   48.84    0.56\n",
    " 10    1600         38.34     24.16   51.96   70.67   41.09    0.52\n",
    " 13    1800        105.14     23.23   56.88   69.66   48.06    0.57\n",
    "\n",
    "✔ Saved pipeline to output directory\n",
    "/path/to/output/model-last"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3f4664-fc05-4d04-9ddc-380cefa16940",
   "metadata": {},
   "source": [
    "Once a model is trained load it the same way as the default models:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f9ba3c3b-9872-42b7-aeea-6777aabedb59",
   "metadata": {},
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"/path/to/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc676e48-cb6f-4ec1-a6ec-77ed87a22403",
   "metadata": {},
   "source": [
    "##### Generating a config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54360c81-2202-4a3b-8586-4782c13f0c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                               \n",
      " Usage: python -m spacy init config [OPTIONS] OUTPUT_FILE                      \n",
      "                                                                               \n",
      " Generate a starter config file for training. Based on your requirements       \n",
      " specified via the CLI arguments, this command generates a config with the     \n",
      " optimal settings for your use case. This includes the choice of architecture, \n",
      " pretrained weights and related hyperparameters.                               \n",
      " DOCS: https://spacy.io/api/cli#init-config                                    \n",
      "                                                                               \n",
      "+- Arguments -----------------------------------------------------------------+\n",
      "| *    output_file      PATH  File to save the config to or - for stdout      |\n",
      "|                             (will only output config and no additional      |\n",
      "|                             logging info)                                   |\n",
      "|                             [default: None]                                 |\n",
      "|                             [required]                                      |\n",
      "+-----------------------------------------------------------------------------+\n",
      "+- Options -------------------------------------------------------------------+\n",
      "| --lang         -l       TEXT                   Two-letter code of the       |\n",
      "|                                                language to use              |\n",
      "|                                                [default: en]                |\n",
      "| --pipeline     -p       TEXT                   Comma-separated names of     |\n",
      "|                                                trainable pipeline           |\n",
      "|                                                components to include        |\n",
      "|                                                (without 'tok2vec' or        |\n",
      "|                                                'transformer')               |\n",
      "|                                                [default: tagger,parser,ner] |\n",
      "| --optimize     -o       [efficiency|accuracy]  Whether to optimize for      |\n",
      "|                                                efficiency (faster           |\n",
      "|                                                inference, smaller model,    |\n",
      "|                                                lower memory consumption) or |\n",
      "|                                                higher accuracy (potentially |\n",
      "|                                                larger and slower model).    |\n",
      "|                                                This will impact the choice  |\n",
      "|                                                of architecture, pretrained  |\n",
      "|                                                weights and related          |\n",
      "|                                                hyperparameters.             |\n",
      "|                                                [default:                    |\n",
      "|                                                Optimizations.efficiency]    |\n",
      "| --gpu          -G                              Whether the model can run on |\n",
      "|                                                GPU. This will impact the    |\n",
      "|                                                choice of architecture,      |\n",
      "|                                                pretrained weights and       |\n",
      "|                                                related hyperparameters.     |\n",
      "| --pretraining  -pt                             Include config for           |\n",
      "|                                                pretraining (with 'spacy     |\n",
      "|                                                pretrain')                   |\n",
      "| --force        -F                              Force overwriting the output |\n",
      "|                                                file                         |\n",
      "| --help                                         Show this message and exit.  |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init config --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "771a3101-202d-4622-9ab6-0dbd342b5fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Generated config template specific for your use case\n",
      "- Language: en\n",
      "- Pipeline: ner\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init config .\\config.cfg --lang en --pipeline ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "921f69a9-e90a-4339-bf20-fe2b1fcca913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[paths]\n",
      "train = null\n",
      "dev = null\n",
      "vectors = null\n",
      "init_tok2vec = null\n",
      "\n",
      "[system]\n",
      "gpu_allocator = null\n",
      "seed = 0\n",
      "\n",
      "[nlp]\n",
      "lang = \"en\"\n",
      "pipeline = [\"tok2vec\",\"ner\"]\n",
      "batch_size = 1000\n",
      "disabled = []\n",
      "before_creation = null\n",
      "after_creation = null\n",
      "after_pipeline_creation = null\n",
      "tokenizer = {\"@tokenizers\":\"spacy.Tokenizer.v1\"}\n",
      "vectors = {\"@vectors\":\"spacy.Vectors.v1\"}\n",
      "\n",
      "[components]\n",
      "\n",
      "[components.ner]\n",
      "factory = \"ner\"\n",
      "incorrect_spans_key = null\n",
      "moves = null\n",
      "scorer = {\"@scorers\":\"spacy.ner_scorer.v1\"}\n",
      "update_with_oracle_cut_size = 100\n",
      "\n",
      "[components.ner.model]\n",
      "@architectures = \"spacy.TransitionBasedParser.v2\"\n",
      "state_type = \"ner\"\n",
      "extra_state_tokens = false\n",
      "hidden_width = 64\n",
      "maxout_pieces = 2\n",
      "use_upper = true\n",
      "nO = null\n",
      "\n",
      "[components.ner.model.tok2vec]\n",
      "@architectures = \"spacy.Tok2VecListener.v1\"\n",
      "width = ${components.tok2vec.model.encode.width}\n",
      "upstream = \"*\"\n",
      "\n",
      "[components.tok2vec]\n",
      "factory = \"tok2vec\"\n",
      "\n",
      "[components.tok2vec.model]\n",
      "@architectures = \"spacy.Tok2Vec.v2\"\n",
      "\n",
      "[components.tok2vec.model.embed]\n",
      "@architectures = \"spacy.MultiHashEmbed.v2\"\n",
      "width = ${components.tok2vec.model.encode.width}\n",
      "attrs = [\"NORM\",\"PREFIX\",\"SUFFIX\",\"SHAPE\"]\n",
      "rows = [5000,1000,2500,2500]\n",
      "include_static_vectors = false\n",
      "\n",
      "[components.tok2vec.model.encode]\n",
      "@architectures = \"spacy.MaxoutWindowEncoder.v2\"\n",
      "width = 96\n",
      "depth = 4\n",
      "window_size = 1\n",
      "maxout_pieces = 3\n",
      "\n",
      "[corpora]\n",
      "\n",
      "[corpora.dev]\n",
      "@readers = \"spacy.Corpus.v1\"\n",
      "path = ${paths.dev}\n",
      "max_length = 0\n",
      "gold_preproc = false\n",
      "limit = 0\n",
      "augmenter = null\n",
      "\n",
      "[corpora.train]\n",
      "@readers = \"spacy.Corpus.v1\"\n",
      "path = ${paths.train}\n",
      "max_length = 0\n",
      "gold_preproc = false\n",
      "limit = 0\n",
      "augmenter = null\n",
      "\n",
      "[training]\n",
      "dev_corpus = \"corpora.dev\"\n",
      "train_corpus = \"corpora.train\"\n",
      "seed = ${system.seed}\n",
      "gpu_allocator = ${system.gpu_allocator}\n",
      "dropout = 0.1\n",
      "accumulate_gradient = 1\n",
      "patience = 1600\n",
      "max_epochs = 0\n",
      "max_steps = 20000\n",
      "eval_frequency = 200\n",
      "frozen_components = []\n",
      "annotating_components = []\n",
      "before_to_disk = null\n",
      "before_update = null\n",
      "\n",
      "[training.batcher]\n",
      "@batchers = \"spacy.batch_by_words.v1\"\n",
      "discard_oversize = false\n",
      "tolerance = 0.2\n",
      "get_length = null\n",
      "\n",
      "[training.batcher.size]\n",
      "@schedules = \"compounding.v1\"\n",
      "start = 100\n",
      "stop = 1000\n",
      "compound = 1.001\n",
      "t = 0.0\n",
      "\n",
      "[training.logger]\n",
      "@loggers = \"spacy.ConsoleLogger.v1\"\n",
      "progress_bar = false\n",
      "\n",
      "[training.optimizer]\n",
      "@optimizers = \"Adam.v1\"\n",
      "beta1 = 0.9\n",
      "beta2 = 0.999\n",
      "L2_is_weight_decay = true\n",
      "L2 = 0.01\n",
      "grad_clip = 1.0\n",
      "use_averages = false\n",
      "eps = 0.00000001\n",
      "learn_rate = 0.001\n",
      "\n",
      "[training.score_weights]\n",
      "ents_f = 1.0\n",
      "ents_p = 0.0\n",
      "ents_r = 0.0\n",
      "ents_per_type = null\n",
      "\n",
      "[pretraining]\n",
      "\n",
      "[initialize]\n",
      "vectors = ${paths.vectors}\n",
      "init_tok2vec = ${paths.init_tok2vec}\n",
      "vocab_data = null\n",
      "lookups = null\n",
      "before_init = null\n",
      "after_init = null\n",
      "\n",
      "[initialize.components]\n",
      "\n",
      "[initialize.tokenizer]\n"
     ]
    }
   ],
   "source": [
    "!type config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93844b15-1d17-417f-9296-52506136b1e1",
   "metadata": {},
   "source": [
    "##### Using the training CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0db8ad75-739b-4998-b98c-92e0e8e8a217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' # Fix for OMP: Error #15: Initializing libiomp5md.dll, but found libiomp5md.dll already initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6199149e-959b-49fa-9665-1500d3a7d4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Saving to output directory: output\n",
      "[i] Using CPU\n",
      "[i] To switch to GPU 0, use the option: --gpu-id 0\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     20.33    1.69    1.04    4.44    0.02\n",
      "  1     200         29.68    982.54   78.69   77.42   80.00    0.79\n",
      "  2     400         73.66    242.14   80.00   76.00   84.44    0.80\n",
      "  4     600         65.99    107.64   81.56   82.02   81.11    0.82\n",
      "  6     800         66.82     75.03   80.23   81.61   78.89    0.80\n",
      "  9    1000        108.99     73.20   86.49   84.21   88.89    0.86\n",
      " 12    1200         39.55     26.12   87.91   86.96   88.89    0.88\n",
      " 16    1400         78.52     39.19   85.56   85.56   85.56    0.86\n",
      " 22    1600         63.65     17.61   82.98   79.59   86.67    0.83\n",
      " 28    1800        138.04     37.72   84.32   82.11   86.67    0.84\n",
      " 36    2000         89.93     21.99   83.98   83.52   84.44    0.84\n",
      " 46    2200         46.61      9.51   85.71   88.24   83.33    0.86\n",
      " 58    2400         38.08     10.33   85.08   84.62   85.56    0.85\n",
      " 70    2600        315.69     59.67   86.67   86.67   86.67    0.87\n",
      " 83    2800         72.91     17.60   85.08   84.62   85.56    0.85\n",
      "[+] Saved pipeline to output directory\n",
      "output\\model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train .\\training\\config_gadget.cfg --output .\\output --paths.train .\\training\\train_gadget.spacy --paths.dev .\\training\\dev_gadget.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd955f0-8fda-4c8e-9092-5663212384c3",
   "metadata": {},
   "source": [
    "##### Best practives to training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119994d2-28b5-4f3c-b920-b627bd141cff",
   "metadata": {},
   "source": [
    "- When training on new categories, mix in previously correct prediction examples to avoid overfitting/forgetting\n",
    "    - Can use old model working well to label data from domain for the new category data\n",
    "- Models will struggle to learn if prediction cannot be made from local context\n",
    "    - Keep category labels broad, not too specific"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
