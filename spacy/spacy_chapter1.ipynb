{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c66b60da-879a-49b9-abb8-6cd02221b59b",
   "metadata": {},
   "source": [
    "#### Advanced NLP with spaCy\n",
    "#### [Chapter 1: Finding words, phrases, names and concepts](https://course.spacy.io/en/chapter1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8dab04-e850-4abc-b2ff-fe968cec2daa",
   "metadata": {},
   "source": [
    "##### 1. Introduction to spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d36607-ccd6-4c36-9b2f-a7a02b2732e4",
   "metadata": {},
   "source": [
    "Creating a blank processing pipeline, which by convention is named 'nlp':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3daeacd-73b4-4892-a3cb-d9e9bb2231c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a12f4d5-a284-4996-afc9-7450f923de16",
   "metadata": {},
   "source": [
    "When you process a text, nlp will return a doc object. It can be used as an iterator where each iteration is a token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a766dd41-7738-467f-b246-d53cbcd84293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "world\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Hello world!\")\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3f7642-9887-449f-b0b4-51028eabd129",
   "metadata": {},
   "source": [
    "Tokens can be retrieved via index positions and slices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff5427b7-f4a2-45cc-a5c2-908ec9806ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world\n"
     ]
    }
   ],
   "source": [
    "token = doc[1]\n",
    "print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54844e1f-1ee5-4584-9bfb-2b0f2b4594ec",
   "metadata": {},
   "source": [
    "Accessing a slice of a doc returns a span obj:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7ea4082-f302-471b-86a2-0cb8ac95b8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world!\n",
      "<class 'spacy.tokens.span.Span'>\n"
     ]
    }
   ],
   "source": [
    "span = doc[1:3]\n",
    "print(span.text)\n",
    "print(type(span))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6c9b47-5cab-4761-89dc-723944e09294",
   "metadata": {},
   "source": [
    "Tokens have a lot of attributes that can be accessed. Here are a few of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50c9ca4a-1be8-4a15-9645-6c586bedad7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:    [0, 1, 2, 3, 4]\n",
      "Text:     ['It', 'costs', '$', '5', '.']\n",
      "is_alpha: [True, True, False, False, False]\n",
      "is_punct: [False, False, False, False, True]\n",
      "like_num: [False, False, False, True, False]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"It costs $5.\")\n",
    "print(\"Index:   \", [token.i for token in doc])\n",
    "print(\"Text:    \", [token.text for token in doc])\n",
    "print(\"is_alpha:\", [token.is_alpha for token in doc])\n",
    "print(\"is_punct:\", [token.is_punct for token in doc])\n",
    "print(\"like_num:\", [token.like_num for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f284a9a3-c683-4b8e-84a1-42a7ec512d17",
   "metadata": {},
   "source": [
    "Note that numbers spelled out are still True for the like_num attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cccb5b9-b98b-4cda-9ef8-817ceeb304d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"That is ten items\")\n",
    "ten = doc[2]\n",
    "print(ten.is_alpha, ten.like_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf44b0e-d699-4977-8cf4-25265a057f13",
   "metadata": {},
   "source": [
    "##### 2. Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34698069-9c2d-48e6-9d34-fc034a6ca258",
   "metadata": {},
   "source": [
    "English:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9349a9ca-445f-4abd-ac61-09712dec6e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence.\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "doc = nlp(\"This is a sentence.\")\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b317e3aa-d62c-42f3-bc84-967354efcbc8",
   "metadata": {},
   "source": [
    "German:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91825bb1-2516-4cec-9982-39d5c131e814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liebe Grüße!\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"de\")\n",
    "doc = nlp(\"Liebe Grüße!\")\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e87cbc1-cf1e-4a9f-8db3-601f03d53203",
   "metadata": {},
   "source": [
    "Spanish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ddaeeed6-8f3a-4896-99c0-ced53bce178f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Cómo estás?\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"es\")\n",
    "doc = nlp(\"¿Cómo estás?\")\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052fba13-6b08-4fba-b85f-0958d599fccf",
   "metadata": {},
   "source": [
    "##### 3. Documents, spans and tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61434da6-5768-446f-8a41-ed1318f74bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "doc = nlp(\"I like tree kangaroos and narwhals.\")\n",
    "first_token = doc[0]\n",
    "print(first_token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0494b7c0-3db4-4dc0-91ee-0142a11bff73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree kangaroos\n"
     ]
    }
   ],
   "source": [
    "tree_kangaroos = doc[2:4]\n",
    "print(tree_kangaroos.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "184309fc-ffca-47db-938e-897830c2e9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree kangaroos and narwhals\n"
     ]
    }
   ],
   "source": [
    "tree_kangaroos_and_narwhals = doc[2:6]\n",
    "print(tree_kangaroos_and_narwhals.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0f4880-213d-429a-8f61-b877a058b676",
   "metadata": {},
   "source": [
    "##### 4. Lexical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c549093-14ed-48e8-a5a4-c72e75579dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage found: 60\n",
      "Percentage found: 4\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\n",
    "    \"In 1990, more than 60% of people in East Asia were in extreme poverty. \"\n",
    "    \"Now less than 4% are.\"\n",
    ")\n",
    "for token in doc:\n",
    "    if token.like_num:\n",
    "        next_token = doc[token.i + 1]\n",
    "        if next_token.text == \"%\":\n",
    "            print(\"Percentage found:\", token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc83230-52c8-4674-8650-b67829765c03",
   "metadata": {},
   "source": [
    "##### 5. Trained pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03c4b55-3f25-4846-9103-baede4f4af06",
   "metadata": {},
   "source": [
    "Trained pipelines are used to make predictions on linguistic attributes like POS tagging, syntatic dependency, and named entities.  \n",
    "They can be fine-tuned with labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "56fa58ed-6d59-46b9-bf2e-37057c2f611f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She PRON nsubj ate\n",
      "ate VERB ROOT ate\n",
      "the DET det pizza\n",
      "pizza NOUN dobj ate\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"She ate the pizza\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_, token.head.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b93889-e7c4-4e00-9c2b-9468fd9ae1f5",
   "metadata": {},
   "source": [
    "Entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a835253-7d9d-4f3e-a138-d8538a5da8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "U.K. GPE\n",
      "$1 billion MONEY\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46637184-d11e-4bf0-aef8-dda85026a89c",
   "metadata": {},
   "source": [
    "Getting info on tags and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8433ea25-21eb-443b-b606-6213b0aad20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries, cities, states\n",
      "noun, proper singular\n",
      "direct object\n"
     ]
    }
   ],
   "source": [
    "print(spacy.explain(\"GPE\"))\n",
    "print(spacy.explain(\"NNP\"))\n",
    "print(spacy.explain(\"dobj\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5e6fcd-95d8-40fd-8b04-2779ad4ba668",
   "metadata": {},
   "source": [
    "##### 6. Pipeline packages\n",
    "Training data is not included in the pipeline package, just the inference model/weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa9a7e5-b66a-454c-a5e1-08babb0ce207",
   "metadata": {},
   "source": [
    "##### 7. Loading pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95f75b70-3cb5-483d-9611-ee8202aabf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
    "doc = nlp(text)\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1941734-8280-48ea-91b8-579a7be4e167",
   "metadata": {},
   "source": [
    "##### 8. Predicting linguistic annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "47ac36e9-051e-40e7-b9bc-c84de86e1527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It          PRON      nsubj     \n",
      "’s          VERB      ccomp     \n",
      "official    NOUN      acomp     \n",
      ":           PUNCT     punct     \n",
      "Apple       PROPN     nsubj     \n",
      "is          AUX       ROOT      \n",
      "the         DET       det       \n",
      "first       ADJ       amod      \n",
      "U.S.        PROPN     nmod      \n",
      "public      ADJ       amod      \n",
      "company     NOUN      attr      \n",
      "to          PART      aux       \n",
      "reach       VERB      relcl     \n",
      "a           DET       det       \n",
      "$           SYM       quantmod  \n",
      "1           NUM       compound  \n",
      "trillion    NUM       nummod    \n",
      "market      NOUN      compound  \n",
      "value       NOUN      dobj      \n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    token_text = token.text\n",
    "    token_pos = token.pos_\n",
    "    token_dep = token.dep_\n",
    "    print(f\"{token_text:<12}{token_pos:<10}{token_dep:<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04e3f5a7-0334-4251-9947-152b13189497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "first ORDINAL\n",
      "U.S. GPE\n",
      "$1 trillion MONEY\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d401af84-5705-4a36-95dd-9b8257733fb6",
   "metadata": {},
   "source": [
    "##### 9. Predicting named entities in context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "653f3942-97f5-4a63-adfc-e1477d609ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "Missing entity: iPhone X\n"
     ]
    }
   ],
   "source": [
    "text = \"Upcoming iPhone X release date leaked as Apple reveals pre-orders\"\n",
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "\n",
    "iphone_x = doc[1:3]\n",
    "print(\"Missing entity:\", iphone_x.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d49fcca-dcfe-4abe-b484-d05118d53a3d",
   "metadata": {},
   "source": [
    "##### 10. Rule-based matching\n",
    "Works on token objects' attributes, for example matching \"duck\" the noun vs \"duck\" the verb.  \n",
    "Match patterns need to be in the form of a list of dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "04aaae44-143b-484a-a402-ba9dc66de1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhone X\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}]\n",
    "matcher.add(\"IPHONE_PATTERN\", [pattern])\n",
    "doc = nlp(\"Upcoming iPhone X release date leaked\")\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa3272ba-059b-4bca-82c7-07e8756fb517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 FIFA World Cup:\n"
     ]
    }
   ],
   "source": [
    "pattern = [\n",
    "    {\"IS_DIGIT\": True},\n",
    "    {\"LOWER\": \"fifa\"},\n",
    "    {\"LOWER\": \"world\"},\n",
    "    {\"LOWER\": \"cup\"},\n",
    "    {\"IS_PUNCT\": True}\n",
    "]\n",
    "doc = nlp(\"2018 FIFA World Cup: France won!\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"WORLD_CUP\", [pattern])\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522dcb46-e515-4614-bd54-9448b2a6d241",
   "metadata": {},
   "source": [
    "Patterns will match on multiple spans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba86d507-a110-4a16-905f-8b6720b31110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loved dogs\n",
      "love cats\n"
     ]
    }
   ],
   "source": [
    "pattern = [\n",
    "    {\"LEMMA\": \"love\", \"POS\": \"VERB\"},\n",
    "    {\"POS\": \"NOUN\"}\n",
    "]\n",
    "doc = nlp(\"I loved dogs but now I love cats more.\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"LOVE\", [pattern])\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de5a5f7-abcf-4ba7-be21-4accff3942aa",
   "metadata": {},
   "source": [
    "You can include quantifiers via the OP key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f2ba8a3a-1f9c-4a43-aca3-a6c56e09aa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bought a smartphone\n",
      "buying apps\n"
     ]
    }
   ],
   "source": [
    "pattern = [\n",
    "    {\"LEMMA\": \"buy\"},\n",
    "    {\"POS\": \"DET\", \"OP\": \"?\"},  # match 0 or 1 times\n",
    "    {\"POS\": \"NOUN\"}\n",
    "]\n",
    "doc = nlp(\"I bought a smartphone. Now I'm buying apps.\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"BUY\", [pattern])\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "96c1721a-28e8-4b07-8d44-cd45458a4aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "{\"OP\": \"!\"}\t# Negation: match 0 times\n",
    "{\"OP\": \"?\"}\t# Optional: match 0 or 1 times\n",
    "{\"OP\": \"+\"}\t# Match 1 or more times\n",
    "{\"OP\": \"*\"}\t# Match 0 or more times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41bda72-c809-46f1-a01c-794a1275f08d",
   "metadata": {},
   "source": [
    "##### 11. Using the Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5606e2e4-af30-4564-a43f-91cf254174ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches: ['iPhone X']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Upcoming iPhone X release date leaked as Apple reveals pre-orders\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}]\n",
    "matcher.add(\"IPHONE_X_PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "print(\"Matches:\", [doc[start:end].text for match_id, start, end in matches])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c554b0-3ac3-4c3b-8f10-dac73539e7fa",
   "metadata": {},
   "source": [
    "##### 12. Writing match patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3605884b-c1d2-4b06-986e-f381317e5997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 3\n",
      "Match found: iOS 7\n",
      "Match found: iOS 11\n",
      "Match found: iOS 10\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "doc = nlp(\n",
    "    \"After making the iOS update you won't notice a radical system-wide \"\n",
    "    \"redesign: nothing like the aesthetic upheaval we got with iOS 7. Most of \"\n",
    "    \"iOS 11's furniture remains the same as in iOS 10. But you will discover \"\n",
    "    \"some tweaks once you delve a little deeper.\"\n",
    ")\n",
    "pattern = [{\"TEXT\": \"iOS\"}, {\"IS_DIGIT\": True}]\n",
    "matcher.add(\"IOS_VERSION_PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "print(\"Total matches found:\", len(matches))\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found:\", doc[start:end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f8dd323d-20a1-4b4f-b7ff-b1b12abccaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 3\n",
      "Match found: downloaded Fortnite\n",
      "Match found: downloading Minecraft\n",
      "Match found: download Winzip\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "doc = nlp(\n",
    "    \"i downloaded Fortnite on my laptop and can't open the game at all. Help? \"\n",
    "    \"so when I was downloading Minecraft, I got the Windows version where it \"\n",
    "    \"is the '.zip' folder and I used the default program to unpack it... do \"\n",
    "    \"I also need to download Winzip?\"\n",
    ")\n",
    "pattern = [{\"LEMMA\": \"download\"}, {\"POS\": \"PROPN\"}]\n",
    "matcher.add(\"DOWNLOAD_THINGS_PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "print(\"Total matches found:\", len(matches))\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found:\", doc[start:end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5279b5c4-19a1-454b-b689-032ddd2dba09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 5\n",
      "Match found: beautiful design\n",
      "Match found: smart search\n",
      "Match found: automatic labels\n",
      "Match found: optional voice\n",
      "Match found: optional voice responses\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "doc = nlp(\n",
    "    \"Features of the app include a beautiful design, smart search, automatic \"\n",
    "    \"labels and optional voice responses.\"\n",
    ")\n",
    "pattern = [{\"POS\": \"ADJ\"}, {\"POS\": \"NOUN\"}, {\"POS\": \"NOUN\", \"OP\": \"?\"}]\n",
    "matcher.add(\"ADJ_NOUN_PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "print(\"Total matches found:\", len(matches))\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found:\", doc[start:end].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
